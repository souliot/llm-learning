{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d43c84d7-0f52-47e9-aa47-5735264f3a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-21 16:17:38,949 - modelscope - WARNING - Model revision not specified, use revision: v2.0.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./modelscope/iic/SenseVoiceSmall\n",
      "You are using the latest version of funasr-1.1.2\n",
      "Loading remote code successfully: model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.012: 100%|\u001b[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 1/1 [00:00<00:00, 19.24it/s]\u001b[0m\n",
      "  0%|\u001b[31m                                              \u001b[0m| 0/1 [00:00<?, ?it/s]\u001b[0m\n",
      "  0%|\u001b[34m                                              \u001b[0m| 0/1 [00:00<?, ?it/s]\u001b[0m\u001b[A\n",
      "{'load_data': '0.000', 'extract_feat': '0.003', 'forward': '0.063', 'batc\u001b[A\n",
      "rtf_avg: 0.023: 100%|\u001b[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 1/1 [00:00<00:00, 14.90it/s]\u001b[0m\u001b[A\n",
      "rtf_avg: 0.027, time_speech:  2.743, time_escape: 0.073: 100%|\u001b[31mâ–ˆ\u001b[0m| 1/1 [00:\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': 'emo_1', 'text': '<|en|><|HAPPY|><|Speech|><|withitn|>I did go and made many prisoners.'}]\n",
      "I did go and made many prisoners.ðŸ˜Š\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from modelscope.hub.snapshot_download import snapshot_download\n",
    "\n",
    "from funasr import AutoModel\n",
    "\n",
    "from utils import format_str_v3\n",
    "\n",
    "basic_model = \"iic/SenseVoiceSmall\"\n",
    "vad_model=\"iic/speech_fsmn_vad_zh-cn-16k-common-pytorch\"\n",
    "\n",
    "basic_model_dir = snapshot_download(basic_model, cache_dir='../modelscope')\n",
    "vad_modell_dir = snapshot_download(vad_model, cache_dir='../modelscope')\n",
    "\n",
    "print(basic_model_dir)\n",
    "\n",
    "model = AutoModel(model=basic_model_dir,\n",
    "\t\t\t\t  vad_model=vad_modell_dir,\n",
    "\t\t\t\t  vad_kwargs={\"max_single_segment_time\": 30000},\n",
    "\t\t\t\t  trust_remote_code=True,\n",
    "\t\t\t\t  )\n",
    "\n",
    "language_abbr = {\"auto\": \"auto\", \"zh\": \"zh\", \"en\": \"en\", \"yue\": \"yue\", \"ja\": \"ja\", \"ko\": \"ko\",\n",
    "\t\t\t\t\t \"nospeech\": \"nospeech\"}\n",
    "\n",
    "language = \"zh\"\n",
    "\n",
    "language = \"auto\" if len(language) < 1 else language\n",
    "\n",
    "selected_language = language_abbr[language]\n",
    "\n",
    "text = model.generate(input='../example/emo_1.wav',\n",
    "\t\t\t\t\t\t  cache={},\n",
    "\t\t\t\t\t\t  language=selected_language,\n",
    "\t\t\t\t\t\t  use_itn=True,\n",
    "\t\t\t\t\t\t  batch_size_s=300, merge_vad=True)\n",
    "\n",
    "print(text)\n",
    "text = text[0][\"text\"]\n",
    "text = format_str_v3(text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b60580-1242-4a6d-a6a9-c4555432f580",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
